{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from pathlib import Path\n",
    "from keras import backend as K\n",
    "from collections import defaultdict\n",
    "from keras.models import load_model\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from fr_utils import *\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)))\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)))\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.maximum(tf.reduce_mean(basic_loss), 0.0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "Rmodel = load_model('my_model.h5', custom_objects={'triplet_loss': triplet_loss})\n",
    "\n",
    "print(\"Total Params:\", Rmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFiles(pathDir2):\n",
    "    pathDir = Path(pathDir2)\n",
    "    files = [p for p in pathDir.iterdir() if p.is_file ()]\n",
    "    return files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pil to load image\n",
    "\n",
    "def PIL2array(img):\n",
    "    return np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "\n",
    "min_side = 600\n",
    "np_imgs = []\n",
    "all_imgs = getAllFiles('images/fulltest/')\n",
    "for cur_img_path in all_imgs:\n",
    "    img = Image.open(cur_img_path)\n",
    "    img = img.convert('RGB')\n",
    "    width, height = img.size\n",
    "    if height < width:\n",
    "        width = int(1.0 * width * min_side / height)\n",
    "        height = min_side\n",
    "    else:\n",
    "        height = int(1.0 * height * min_side / width)\n",
    "        width = min_side\n",
    "    size = width + 1, height + 1\n",
    "    img = img.resize(size)\n",
    "    tmp = PIL2array(img)\n",
    "    np_imgs.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using cv2 to load image that 8 times faster than pil\n",
    "\n",
    "min_side = 600\n",
    "np_imgs = []\n",
    "all_imgs = getAllFiles('images/fulltest/')\n",
    "\n",
    "for cur_img_path in all_imgs:\n",
    "    tmp = cv2.imread(str(cur_img_path), 1)\n",
    "    height = tmp.shape[0]\n",
    "    width = tmp.shape[1]\n",
    "    if height < width:\n",
    "        width = int(1.0 * width * min_side / height)\n",
    "        height = min_side\n",
    "    else:\n",
    "        height = int(1.0 * height * min_side / width)\n",
    "        width = min_side\n",
    "\n",
    "    tmp = cv2.resize(tmp,(width + 1, height + 1)) \n",
    "    np_imgs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 200\n",
    "stride = 100\n",
    "\n",
    "mat = []\n",
    "encodings = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for row in range(0, int(3 * min_side / 2), stride):\n",
    "    for col in range(0, int(3 * min_side / 2), stride):\n",
    "        mat.append([row, col])\n",
    "\n",
    "\n",
    "for cur_img in np_imgs:\n",
    "    tmp = []\n",
    "    for r in mat:\n",
    "        if cur_img.shape[0] - dim > r[0] and cur_img.shape[1] - dim > r[1]:\n",
    "            tmp.append(img_to_encoding_range(dim, r[0], r[1], cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding(cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding_bot(cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding_top(cur_img, Rmodel))\n",
    "    encodings.append(tmp)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_find(tree_size):\n",
    "    for i in range(0, tree_size):\n",
    "        par.append(i)\n",
    "\n",
    "def get_par(cur_node):\n",
    "    if cur_node == par[cur_node]:\n",
    "        return cur_node\n",
    "    else:\n",
    "        par[cur_node] = get_par(par[cur_node])\n",
    "        return par[cur_node]\n",
    "\n",
    "def merge(a, b):\n",
    "    a = get_par(a)\n",
    "    b = get_par(b)\n",
    "    par[a] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_EPS = 0.94\n",
    "MAX_EPS = 1.04\n",
    "\n",
    "def size_compare(a, b):\n",
    "    ret = (1.0 * a[0] * b[1]) / (1.0 * a[1] * b[0]) \n",
    "    if ret > MIN_EPS and ret < MAX_EPS:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par = []\n",
    "union_find(len(encodings))\n",
    "for i in range(0, len(encodings)):\n",
    "    for j in range(i + 1, len(encodings)):\n",
    "        if size_compare(np_imgs[i].shape, np_imgs[j].shape) == False:\n",
    "            continue\n",
    "        cnt = 0\n",
    "        size = min(len(encodings[i]), len(encodings[j]))\n",
    "        for k in range(0, size):\n",
    "            dist = np.linalg.norm(encodings[i][k]-encodings[j][k])\n",
    "            if dist < 0.42:\n",
    "                cnt += 1\n",
    "        if cnt > size / 4 + 1:\n",
    "            merge(i, j)\n",
    "        \n",
    "d = defaultdict(list)\n",
    "for i in range(0, len(encodings)):\n",
    "    cur_par = get_par(i)\n",
    "    d[cur_par].append(all_imgs[i])\n",
    "\n",
    "failed = 0\n",
    "\n",
    "for cur_par in d:\n",
    "    print(\"----------------------------\")\n",
    "    print(\"Parent : \", cur_par)\n",
    "    print(\"----------------------------\")\n",
    "    print(d[cur_par])\n",
    "    if len(d[cur_par]) == 1:\n",
    "        failed += 1\n",
    "    #    print(d[cur_par])\n",
    "print(len(d))\n",
    "print(failed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
