{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from pathlib import Path\n",
    "from keras import backend as K\n",
    "from collections import defaultdict\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmodel = RecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", Rmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)))\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)))\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.maximum(tf.reduce_mean(basic_loss), 0.0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "weights = WEIGHTS\n",
    "weights_dict = load_weights()\n",
    "\n",
    "for name in weights:\n",
    "    Rmodel.get_layer(name).set_weights(weights_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFiles(pathDir2):\n",
    "    pathDir = Path(pathDir2)\n",
    "    files = [p for p in pathDir.iterdir() if p.is_file()]\n",
    "    return files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_side = 600\n",
    "np_imgs = []\n",
    "all_imgs = getAllFiles('images/same/')\n",
    "\n",
    "for cur_img_path in all_imgs:\n",
    "    tmp = cv2.imread(str(cur_img_path), 1)\n",
    "    height = tmp.shape[0]\n",
    "    width = tmp.shape[1]\n",
    "    if height < width:\n",
    "        width = int(1.0 * width * min_side / height)\n",
    "        height = min_side\n",
    "    else:\n",
    "        height = int(1.0 * height * min_side / width)\n",
    "        width = min_side\n",
    "\n",
    "    tmp = cv2.resize(tmp,(width + 1, height + 1)) \n",
    "    np_imgs.append(tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.595202922821045\n"
     ]
    }
   ],
   "source": [
    "dim = 200\n",
    "stride = 100\n",
    "\n",
    "mat = []\n",
    "encodings = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for row in range(0, int(3 * min_side / 2), stride):\n",
    "    for col in range(0, int(3 * min_side / 2), stride):\n",
    "        mat.append([row, col])\n",
    "\n",
    "\n",
    "for cur_img in np_imgs:\n",
    "    tmp = []\n",
    "    for r in mat:\n",
    "        if cur_img.shape[0] - dim > r[0] and cur_img.shape[1] - dim > r[1]:\n",
    "            tmp.append(img_to_encoding_range(dim, r[0], r[1], cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding(cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding_bot(cur_img, Rmodel))\n",
    "    tmp.append(img_to_encoding_top(cur_img, Rmodel))\n",
    "    encodings.append(tmp)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_find(tree_size):\n",
    "    for i in range(0, tree_size):\n",
    "        par.append(i)\n",
    "\n",
    "def get_par(cur_node):\n",
    "    if cur_node == par[cur_node]:\n",
    "        return cur_node\n",
    "    else:\n",
    "        par[cur_node] = get_par(par[cur_node])\n",
    "        return par[cur_node]\n",
    "\n",
    "def merge(a, b):\n",
    "    a = get_par(a)\n",
    "    b = get_par(b)\n",
    "    par[a] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_EPS = 0.94\n",
    "MAX_EPS = 1.04\n",
    "\n",
    "def size_compare(a, b):\n",
    "    ret = (1.0 * a[0] * b[1]) / (1.0 * a[1] * b[0]) \n",
    "    if ret > MIN_EPS and ret < MAX_EPS:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Parent :  23\n",
      "----------------------------\n",
      "[PosixPath('images/same/7257_1.jpg'), PosixPath('images/same/7257_2.jpg'), PosixPath('images/same/2631_1.jpg'), PosixPath('images/same/2631_2.jpg')]\n",
      "----------------------------\n",
      "Parent :  16\n",
      "----------------------------\n",
      "[PosixPath('images/same/1089_3.jpg'), PosixPath('images/same/1089_1.jpg'), PosixPath('images/same/1089_2.jpg')]\n",
      "----------------------------\n",
      "Parent :  18\n",
      "----------------------------\n",
      "[PosixPath('images/same/8385_4.jpg'), PosixPath('images/same/8385_5.jpg'), PosixPath('images/same/8385_6.jpg')]\n",
      "----------------------------\n",
      "Parent :  20\n",
      "----------------------------\n",
      "[PosixPath('images/same/9938_4.jpg'), PosixPath('images/same/9938_3.jpg')]\n",
      "----------------------------\n",
      "Parent :  8\n",
      "----------------------------\n",
      "[PosixPath('images/same/7254_4.jpg'), PosixPath('images/same/7254_3.jpg'), PosixPath('images/same/7254_2.jpg')]\n",
      "----------------------------\n",
      "Parent :  21\n",
      "----------------------------\n",
      "[PosixPath('images/same/6239_2.jpg'), PosixPath('images/same/6239_4.jpg'), PosixPath('images/same/6239_1.jpg')]\n",
      "----------------------------\n",
      "Parent :  22\n",
      "----------------------------\n",
      "[PosixPath('images/same/9380_1.jpg'), PosixPath('images/same/9380_2.jpg')]\n",
      "----------------------------\n",
      "Parent :  17\n",
      "----------------------------\n",
      "[PosixPath('images/same/10068_2.jpg'), PosixPath('images/same/10068_3.jpg')]\n",
      "----------------------------\n",
      "Parent :  15\n",
      "----------------------------\n",
      "[PosixPath('images/same/8385_3.jpg')]\n",
      "----------------------------\n",
      "Parent :  24\n",
      "----------------------------\n",
      "[PosixPath('images/same/7650_2.jpg'), PosixPath('images/same/7650_1.jpg')]\n",
      "10\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "par = []\n",
    "union_find(len(encodings))\n",
    "for i in range(0, len(encodings)):\n",
    "    for j in range(i + 1, len(encodings)):\n",
    "        if size_compare(np_imgs[i].shape, np_imgs[j].shape) == False:\n",
    "            continue\n",
    "        cnt = 0\n",
    "        size = min(len(encodings[i]), len(encodings[j]))\n",
    "        for k in range(0, size):\n",
    "            dist = np.linalg.norm(encodings[i][k]-encodings[j][k])\n",
    "            if dist < 0.42:\n",
    "                cnt += 1\n",
    "        if cnt > size / 4 + 1:\n",
    "            merge(i, j)\n",
    "        \n",
    "d = defaultdict(list)\n",
    "for i in range(0, len(encodings)):\n",
    "    cur_par = get_par(i)\n",
    "    d[cur_par].append(all_imgs[i])\n",
    "\n",
    "failed = 0\n",
    "\n",
    "for cur_par in d:\n",
    "    print(\"----------------------------\")\n",
    "    print(\"Parent : \", cur_par)\n",
    "    print(\"----------------------------\")\n",
    "    print(d[cur_par])\n",
    "    if len(d[cur_par]) == 1:\n",
    "        failed += 1\n",
    "    #    print(d[cur_par])\n",
    "print(len(d))\n",
    "print(failed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
